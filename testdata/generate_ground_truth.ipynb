{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validates randomly generated list-based ODs directly on the data\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_counts(x: pd.Series):\n",
    "    return len(x.unique())\n",
    "\n",
    "def colsToString(cols: tuple[str], directions: tuple[bool]):\n",
    "        return f\",\".join([col + (\"↑\" if direction else \"↓\") for col, direction in zip(cols, directions)])\n",
    "\n",
    "\n",
    "class ListBasedDependency():\n",
    "    def __init__(self, df: pd.DataFrame, lhs: list[str], lhsDirection: list[bool], rhs: list[str], rhsDirection : list[bool]) -> None:\n",
    "        self.df = df\n",
    "        self.df = pd.concat([self.df, self.df.isna().add_suffix(\"_isna\")],axis=1)\n",
    "        self.lhs = lhs\n",
    "        self.lhsDirection = lhsDirection\n",
    "        self.rhs = rhs\n",
    "        self.rhsDirection = rhsDirection\n",
    "        \n",
    "    # ensure propoer null first sorting by first sorting by _isna columns\n",
    "    # returns (columns, direction)\n",
    "    def create_sort_args(self, columns, direction):\n",
    "        sort_cols = []\n",
    "        sort_directions = []\n",
    "        for col, dir in zip(columns, direction):\n",
    "            sort_cols.append(col + \"_isna\")\n",
    "            sort_directions.append(True)\n",
    "            sort_cols.append(col)\n",
    "            sort_directions.append(dir)\n",
    "        return sort_cols, sort_directions\n",
    "         \n",
    "    \n",
    "    def isValid(self):\n",
    "        # no splits\n",
    "        df_fd_check = self.df.groupby(self.lhs,dropna=False).agg({col: unique_counts for col in self.rhs})\n",
    "        if not (df_fd_check == 1).all(axis=None):\n",
    "             return False\n",
    "        \n",
    "        # no swaps\n",
    "        lhs, lhsDirection = self.create_sort_args(self.lhs, self.lhsDirection)\n",
    "        sorted_by_lhs = self.df.sort_values(lhs, ascending=lhsDirection)\n",
    "        rhs, rhsDirection = self.create_sort_args(self.rhs, self.rhsDirection)\n",
    "        sorted_by_rhs = sorted_by_lhs.sort_values(rhs, ascending=rhsDirection,kind=\"stable\")\n",
    "        return (sorted_by_lhs.index == sorted_by_rhs.index).all()\n",
    "    \n",
    "    def __str__(self):\n",
    "        result = \"[\"\n",
    "        result += colsToString(self.lhs, self.lhsDirection)\n",
    "        result += \"] -> [\"\n",
    "        result += colsToString(self.rhs, self.rhsDirection)\n",
    "        result += \"]\"\n",
    "        return result    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def isPrefixOf(listA, listB):\n",
    "    if(len(listB) < len(listA)):\n",
    "        return False\n",
    "    for i in range(len(listA)):\n",
    "        if listA[i] != listB[i]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def generateCnadidates(df, valid_amount = 100, max_side_length=6, max_tries = 10_000):\n",
    "    df.fillna(-np.inf,inplace=True)\n",
    "    valids = set()\n",
    "    invalids = set()\n",
    "    starttime = datetime.now()\n",
    "    max_side_length = min(max_side_length, len(df.columns))\n",
    "    i = 0\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"{i=}\")\n",
    "    while len(valids) < valid_amount and i < max_tries:\n",
    "        i += 1\n",
    "        if datetime.now() - starttime > timedelta(minutes=10):\n",
    "            print(f\"Cancel after timeout with {len(valids)=} and {len(invalids)=}\")\n",
    "            return valids, invalids\n",
    "        lhsSize = random.randint(1,max_side_length)\n",
    "        rhsSize = random.randint(1,max_side_length)\n",
    "        lhs = random.sample(sorted(df.columns), lhsSize)\n",
    "        rhs = random.sample(sorted(df.columns), rhsSize)\n",
    "        lhsDirection = [random.choice([True, False]) for _ in range(lhsSize)]\n",
    "        rhsDirection = [random.choice([True, False]) for _ in range(rhsSize)]\n",
    "        \n",
    "        # skpi trivial ODs\n",
    "        if isPrefixOf(rhsDirection, lhsDirection) or isPrefixOf(rhs,lhs):\n",
    "            continue\n",
    "\n",
    "        od = ListBasedDependency(df, lhs, lhsDirection, rhs, rhsDirection)\n",
    "\n",
    "        if od.isValid():\n",
    "            valids.add(str(od))\n",
    "\n",
    "            if len(valids) % 10 == 0:\n",
    "                print(f\"{len(valids)=}\")\n",
    "            \n",
    "        elif len(invalids) < 10_000:\n",
    "            invalids.add(str(od))\n",
    "    return valids, invalids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path(\"/Users/paulsieben/HPI/WiSe 2023-2024 Advanced Data Profiling/Example Data and ODs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6107fda674d14c939a3a5dc35c7d8392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/paulsieben/HPI/WiSe 2023-2024 Advanced Data Profiling/Example Data and ODs/datasets/baseball/els_teamnames.csv\n",
      "i=0\n",
      "len(valids)=10\n",
      "len(valids)=20\n",
      "len(valids)=30\n",
      "len(valids)=40\n",
      "len(valids)=50\n",
      "len(valids)=60\n",
      "len(valids)=70\n",
      "len(valids)=80\n",
      "len(valids)=90\n",
      "len(valids)=100\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "result_path = Path('/Users/paulsieben/Programming/OrderDependencyTester/testdata')\n",
    "for file in tqdm((root_path / \"datasets\").glob(\"**/*\")):\n",
    "    if file.is_dir() or not file.name.endswith('.csv'): continue\n",
    "    valid_path = result_path / \"candidates\" / str(file.parent.name)/ (str(file.name) + \".valids.txt\")\n",
    "    invalid_path = result_path / \"candidates\" / str(file.parent.name)/ (str(file.name) + \".invalids.txt\")\n",
    "    if valid_path.exists() and invalid_path.exists(): continue\n",
    "    print(file)\n",
    "\n",
    "    valids, invalids = generateCnadidates(pd.read_csv(file,sep='\\t',keep_default_na=False, na_values=['', 'null','?']))\n",
    "\n",
    "    valid_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    valid_path.write_text('\\n'.join(valids))\n",
    "\n",
    "    invalid_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    invalid_path.write_text('\\n'.join(invalids))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
